{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FTT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rtdl\n",
        "!pip install libzero==0.0.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPxUAotQ-EEj",
        "outputId": "c4885682-7158-4374-dd09-bccd2e64aafb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rtdl\n",
            "  Downloading rtdl-0.0.13-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.18 in /usr/local/lib/python3.7/dist-packages (from rtdl) (1.21.6)\n",
            "Requirement already satisfied: torch<2,>=1.7 in /usr/local/lib/python3.7/dist-packages (from rtdl) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.7->rtdl) (4.2.0)\n",
            "Installing collected packages: rtdl\n",
            "Successfully installed rtdl-0.0.13\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting libzero==0.0.4\n",
            "  Downloading libzero-0.0.4-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.17 in /usr/local/lib/python3.7/dist-packages (from libzero==0.0.4) (1.21.6)\n",
            "Collecting pynvml<9,>=8.0\n",
            "  Downloading pynvml-8.0.4-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: tqdm<5,>=4.0 in /usr/local/lib/python3.7/dist-packages (from libzero==0.0.4) (4.64.0)\n",
            "Requirement already satisfied: torch<2,>=1.6 in /usr/local/lib/python3.7/dist-packages (from libzero==0.0.4) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.6->libzero==0.0.4) (4.2.0)\n",
            "Installing collected packages: pynvml, libzero\n",
            "Successfully installed libzero-0.0.4 pynvml-8.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhxlkszqCu_q",
        "outputId": "cffa9873-ceed-4b83-b543-8984bec1dc51"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/output-2.zip "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Wyqj20DCw1_",
        "outputId": "a21fcfa4-9c23-4ff3-9958-316ad9192454"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/output-2.zip\n",
            "   creating: data/\n",
            "   creating: data/lenta_evaluating/\n",
            "  inflating: data/lenta_evaluating/C_eval.npy  \n",
            "  inflating: data/lenta_evaluating/N_eval.npy  \n",
            "   creating: data/lenta_training/\n",
            "  inflating: data/lenta_training/y_train.npy  \n",
            "  inflating: data/lenta_training/N_test.npy  \n",
            "  inflating: data/lenta_training/C_train.npy  \n",
            "  inflating: data/lenta_training/y_test.npy  \n",
            "  inflating: data/lenta_training/y_val.npy  \n",
            "  inflating: data/lenta_training/C_test.npy  \n",
            "  inflating: data/lenta_training/N_train.npy  \n",
            "  inflating: data/lenta_training/N_val.npy  \n",
            "  inflating: data/lenta_training/C_val.npy  \n",
            "   creating: data/lenta/\n",
            "  inflating: data/lenta/merged_train.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, Dict\n",
        "\n",
        "import numpy as np\n",
        "import rtdl\n",
        "import scipy.special\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import sklearn.preprocessing\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import zero"
      ],
      "metadata": {
        "id": "0Zojjewo_M24"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "zero.improve_reproducibility(seed=123456)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4J5GPyI_Z9A",
        "outputId": "d3670921-6588-42c0-b5e1-2719fd75f1da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "123456"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task_type = 'regression'"
      ],
      "metadata": {
        "id": "kqPMM9UmDYup"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2yo-brXIA4h",
        "outputId": "c3d99176-2c30-465d-c281-51740f89f292"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.5.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.3.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->category_encoders) (2022.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from category_encoders import CatBoostEncoder"
      ],
      "metadata": {
        "id": "9CxU6rjeIEtD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_dataset = '/content/data/lenta_training'\n",
        "C_train = np.load(path_to_dataset + '/C_train.npy', allow_pickle=True)\n",
        "N_train = np.load(path_to_dataset + '/N_train.npy').astype('float32')\n",
        "y_train = np.load(path_to_dataset + '/y_train.npy').astype('float32')\n",
        "cbe = CatBoostEncoder()\n",
        "C_train = cbe.fit_transform(C_train, y_train).values.astype('float32')\n",
        "C_val = cbe.transform(np.load(path_to_dataset + '/C_val.npy', allow_pickle=True)).values.astype('float32')\n",
        "N_val = np.load(path_to_dataset + '/N_val.npy').astype('float32')\n",
        "y_val = np.load(path_to_dataset + '/y_val.npy').astype('float32')\n",
        "C_test = cbe.transform(np.load(path_to_dataset + '/C_test.npy', allow_pickle=True)).values.astype('float32')\n",
        "N_test = np.load(path_to_dataset + '/N_test.npy').astype('float32')\n",
        "y_test = np.load(path_to_dataset + '/y_test.npy').astype('float32')"
      ],
      "metadata": {
        "id": "QWeflRGTDiky"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, X_test = [np.concatenate([C, N], axis=1) for C, N in zip([C_train, C_val, C_test], [N_train, N_val, N_test])]"
      ],
      "metadata": {
        "id": "ufvDKJk6IfXi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imp = SimpleImputer()\n",
        "X = {}\n",
        "y = {}\n",
        "X['train'],  X['val'], X['test'], y['train'], y['val'], y['test'] = X_train, X_val, X_test, y_train, y_val, y_test\n",
        "preprocess = sklearn.preprocessing.StandardScaler().fit(X['train'])\n",
        "impute = imp.fit(X['train'])\n",
        "\n",
        "X = {\n",
        "    k: impute.fit_transform(v)\n",
        "    for k, v in X.items()\n",
        "}\n",
        "X = {\n",
        "    k: torch.tensor(preprocess.fit_transform(v), device=device)\n",
        "    for k, v in X.items()\n",
        "}\n",
        "y = {k: torch.tensor(v, device=device) for k, v in y.items()}\n",
        "\n",
        "# !!! CRUCIAL for neural networks when solving regression problems !!!\n",
        "if task_type == 'regression':\n",
        "    y_mean = y['train'].mean().item()\n",
        "    y_std = y['train'].std().item()\n",
        "    y = {k: (v - y_mean) / y_std for k, v in y.items()}\n",
        "else:\n",
        "    y_std = y_mean = None\n",
        "\n",
        "if task_type != 'multiclass':\n",
        "    y = {k: v.float() for k, v in y.items()}"
      ],
      "metadata": {
        "id": "diO7M0kq_F5h"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выбрал модель FT-Transformer, так как при должном обучении она выучивается на табличных данных сравнимо с CatBoost: https://arxiv.org/abs/2106.11959\n",
        "\n",
        "Еще один плюс – как PyTorch модель она дифференцируема, соответственно, поэтому я и отказался от использования CatBoost (который учить гораздо комфортнее), чтобы не заниматься black-box оптимизацией (что гораздо более сложная задача, на мой взгляд), а оптимизироваться по градиенту (а еще можно достаточно разумно включить в модель ценообразования информацию о других переменных, которые мы не можем менять)."
      ],
      "metadata": {
        "id": "eeC2Rr8b0TbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_out =  1\n",
        "model = rtdl.FTTransformer.make_default(\n",
        "    n_num_features=X_train.shape[1],\n",
        "    cat_cardinalities=None,\n",
        "    last_layer_query_idx=[-1],  \n",
        "    d_out=d_out,\n",
        ")\n",
        "\n",
        "lr = 1e-4\n",
        "weight_decay = 0.0\n",
        "\n",
        "model.to(device)\n",
        "optimizer = (\n",
        "    model.make_default_optimizer()\n",
        "    if isinstance(model, rtdl.FTTransformer)\n",
        "    else torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        ")\n",
        "loss_fn = (\n",
        "    F.binary_cross_entropy_with_logits\n",
        "    if task_type == 'binclass'\n",
        "    else F.cross_entropy\n",
        "    if task_type == 'multiclass'\n",
        "    else F.mse_loss\n",
        ")"
      ],
      "metadata": {
        "id": "M90t8GLc_fpn"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_model(x_num, x_cat=None):\n",
        "    if isinstance(model, rtdl.FTTransformer):\n",
        "        return model(x_num, x_cat)\n",
        "    elif isinstance(model, (rtdl.MLP, rtdl.ResNet)):\n",
        "        assert x_cat is None\n",
        "        return model(x_num)\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            f'Looks like you are using a custom model: {type(model)}.'\n",
        "            ' Then you have to implement this branch first.'\n",
        "        )\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(part):\n",
        "    model.eval()\n",
        "    prediction = []\n",
        "    for batch in zero.iter_batches(X[part], 1024):\n",
        "        prediction.append(apply_model(batch))\n",
        "    prediction = torch.relu(torch.cat(prediction)).squeeze(1).cpu().numpy()\n",
        "    target = y[part].cpu().numpy()\n",
        "    if task_type == 'binclass':\n",
        "        prediction = np.round(scipy.special.expit(prediction))\n",
        "        score = sklearn.metrics.accuracy_score(target, prediction)\n",
        "    elif task_type == 'multiclass':\n",
        "        prediction = prediction.argmax(1)\n",
        "        score = sklearn.metrics.accuracy_score(target, prediction)\n",
        "    else:\n",
        "        assert task_type == 'regression'\n",
        "        score = sklearn.metrics.mean_squared_error(target, prediction) ** 0.5 * y_std\n",
        "    return score\n",
        "\n",
        "batch_size = 256\n",
        "train_loader = zero.data.IndexLoader(len(X['train']), batch_size, device=device)\n",
        "\n",
        "\n",
        "progress = zero.ProgressTracker(patience=100)\n",
        "\n",
        "print(f'Test score before training: {evaluate(\"test\"):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS1QqOdzABRV",
        "outputId": "944ccc66-664a-41d0-d4f3-05e8b233054d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score before training: 2.6789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "report_frequency = len(X['train']) // batch_size // 5\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    for iteration, batch_idx in enumerate(train_loader):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        x_batch = X['train'][batch_idx]\n",
        "        y_batch = y['train'][batch_idx]\n",
        "        loss = loss_fn(apply_model(x_batch).squeeze(1), y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if iteration % report_frequency == 0:\n",
        "            print(f'(epoch) {epoch} (batch) {iteration} (loss) {loss.item():.4f}')\n",
        "\n",
        "    val_score = evaluate('val')\n",
        "    test_score = evaluate('test')\n",
        "    print(f'Epoch {epoch:03d} | Validation score: {val_score:.4f} | Test score: {test_score:.4f}', end='')\n",
        "    progress.update((-1 if task_type == 'regression' else 1) * val_score)\n",
        "    if progress.success:\n",
        "        print(' <<< BEST VALIDATION EPOCH', end='')\n",
        "    print()\n",
        "    if progress.fail:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BARsPNtMTSa",
        "outputId": "1db70bc9-c852-4a7e-9af9-d2405f06b7de"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(epoch) 1 (batch) 0 (loss) 0.4695\n",
            "(epoch) 1 (batch) 1922 (loss) 0.0915\n",
            "(epoch) 1 (batch) 3844 (loss) 0.1886\n",
            "(epoch) 1 (batch) 5766 (loss) 0.2865\n",
            "(epoch) 1 (batch) 7688 (loss) 0.1339\n",
            "(epoch) 1 (batch) 9610 (loss) 0.1435\n",
            "Epoch 001 | Validation score: 2.2283 | Test score: 2.4936 <<< BEST VALIDATION EPOCH\n",
            "(epoch) 2 (batch) 0 (loss) 0.8139\n",
            "(epoch) 2 (batch) 1922 (loss) 0.0891\n",
            "(epoch) 2 (batch) 3844 (loss) 0.1919\n",
            "(epoch) 2 (batch) 5766 (loss) 0.2828\n",
            "(epoch) 2 (batch) 7688 (loss) 0.1318\n",
            "(epoch) 2 (batch) 9610 (loss) 0.1457\n",
            "Epoch 002 | Validation score: 2.2055 | Test score: 2.4659 <<< BEST VALIDATION EPOCH\n",
            "(epoch) 3 (batch) 0 (loss) 0.2952\n",
            "(epoch) 3 (batch) 1922 (loss) 0.0843\n",
            "(epoch) 3 (batch) 3844 (loss) 0.1853\n",
            "(epoch) 3 (batch) 5766 (loss) 0.2842\n",
            "(epoch) 3 (batch) 7688 (loss) 0.1348\n",
            "(epoch) 3 (batch) 9610 (loss) 0.1471\n",
            "Epoch 003 | Validation score: 2.1886 | Test score: 2.4430 <<< BEST VALIDATION EPOCH\n",
            "(epoch) 4 (batch) 0 (loss) 0.3099\n",
            "(epoch) 4 (batch) 1922 (loss) 0.0769\n",
            "(epoch) 4 (batch) 3844 (loss) 0.1850\n",
            "(epoch) 4 (batch) 5766 (loss) 0.2848\n",
            "(epoch) 4 (batch) 7688 (loss) 0.1331\n",
            "(epoch) 4 (batch) 9610 (loss) 0.1462\n",
            "Epoch 004 | Validation score: 2.1699 | Test score: 2.4106 <<< BEST VALIDATION EPOCH\n",
            "(epoch) 5 (batch) 0 (loss) 0.2791\n",
            "(epoch) 5 (batch) 1922 (loss) 0.0829\n",
            "(epoch) 5 (batch) 3844 (loss) 0.1874\n",
            "(epoch) 5 (batch) 5766 (loss) 0.2839\n",
            "(epoch) 5 (batch) 7688 (loss) 0.1315\n",
            "(epoch) 5 (batch) 9610 (loss) 0.1437\n",
            "Epoch 005 | Validation score: 2.1549 | Test score: 2.3867 <<< BEST VALIDATION EPOCH\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def wape(y_true: np.array, y_pred: np.array):\n",
        "  return np.sum(np.abs(y_true-y_pred))/np.sum(np.abs(y_true))\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_wape(part):\n",
        "    model.eval()\n",
        "    prediction = []\n",
        "    for batch in zero.iter_batches(X[part], 1024):\n",
        "        prediction.append(apply_model(batch))\n",
        "    prediction = torch.relu(torch.cat(prediction)).squeeze(1).cpu().numpy()\n",
        "    target = y[part].cpu().numpy()\n",
        "    prediction = prediction * y_std + y_mean\n",
        "    target = target * y_std + y_mean\n",
        "    score = wape(target, prediction)\n",
        "    return score\n",
        "\n",
        "batch_size = 256\n",
        "progress = zero.ProgressTracker(patience=100)\n",
        "\n",
        "print(f'WAPE: {evaluate_wape(\"test\"):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J1tYSRyQmXq",
        "outputId": "1650c649-780e-4fca-bb3c-b150f0068783"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WAPE: 0.4931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_eval = '/content/data/lenta_evaluating'\n",
        "C = cbe.transform(np.load(path_to_eval + '/C_eval.npy', allow_pickle=True)).values.astype('float32')\n",
        "N = np.load(path_to_eval + '/N_eval.npy').astype('float32')\n",
        "X_eval = np.concatenate([C, N], axis=1) \n",
        "X_eval = preprocess.transform(impute.transform(X_evel)).astype('float32')"
      ],
      "metadata": {
        "id": "tlptPL8zSJyU"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "9ii1RRWPoFI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_eval = torch.tensor(X_eval).to(device)"
      ],
      "metadata": {
        "id": "y35eHnJWTbOW"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del C, N, C_train, N_train"
      ],
      "metadata": {
        "id": "uBFVzWkzVXyc"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def make_preds():\n",
        "    model.eval()\n",
        "    prediction = []\n",
        "    for iteration, batch_idx in enumerate(preds_loader):\n",
        "        x_batch = X_eval[batch_idx]\n",
        "        prediction.append(apply_model(x_batch))\n",
        "    prediction = torch.relu(torch.cat(prediction)).squeeze(1).cpu().numpy()\n",
        "    prediction = prediction * y_std + y_mean\n",
        "    return prediction, iteration\n",
        "preds_loader = zero.data.IndexLoader(len(X_eval), batch_size, device=device, shuffle=False)\n",
        "batch_size = 1024\n",
        "preds, batch_idx = make_preds()"
      ],
      "metadata": {
        "id": "7G-yHqZwUOlX"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9Z5UDS3XovQ",
        "outputId": "4a7182f2-ec1d-42c7-fec2-6559a12ff308"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2666217,)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('preds2.npy', preds)"
      ],
      "metadata": {
        "id": "ZwOb5W3yV0X-"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, optim\n",
        "\n",
        "from itertools import chain\n",
        "\n",
        "class PriceOptim(nn.Module):\n",
        "    def __init__(self, C_shape, N_shape, num_hidden, num_units):\n",
        "      super(PriceOptim, self).__init__()\n",
        "\n",
        "      self.C_shape, self.N_shape = C_shape, N_shape\n",
        "      self.num_hidden, self.num_units = num_hidden, num_units\n",
        "\n",
        "      self.mask = torch.zeros(self.C_shape[1] + self.N_shape[1]).to('cuda' if torch.cuda.is_available() else 'cpu').float()\n",
        "      \n",
        "      self.mask[15:18] = 1.\n",
        "\n",
        "      self.Linear = nn.Sequential(\n",
        "          nn.Linear(self.C_shape[1] + self.N_shape[1], self.num_units),\n",
        "          nn.ReLU(),\n",
        "          *list(chain.from_iterable([[nn.Linear(self.num_units, self.num_units),\n",
        "          nn.ReLU()] for i in range(self.num_hidden)])),\n",
        "          nn.Linear(self.num_units, 1),\n",
        "          nn.ReLU()\n",
        "      )\n",
        "\n",
        "    def forward(self, input):\n",
        "      embedding = self.Linear(input)\n",
        "      #да, немного странно одинаковую цену подавать, тк люди лучше реагируют на скидки, но для простоты моделирования\n",
        "      output = input * (1. - self.mask) + torch.tile(embedding, [1, self.mask.shape[0]])  * self.mask\n",
        "      return output"
      ],
      "metadata": {
        "id": "XGKKzcNZPofy"
      },
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_opt = PriceOptim((0, 13), (0, 12), 2, 25).to(device)"
      ],
      "metadata": {
        "id": "Dt9-xibMbdJn"
      },
      "execution_count": 326,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(price_opt.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "Hofpgn_BcqOm"
      },
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def get_real_revenue():\n",
        "  num_sales_real = torch.relu(apply_model(x_batch).detach()) * y_std + y_mean\n",
        "  price_real = x_batch[:, 16:19]\n",
        "  rev_real = torch.sum(num_sales_real * price_real, axis=1).mean()\n",
        "  return rev_real\n",
        "\n",
        "def get_opt_revenue():\n",
        "   output = price_opt(x_batch)\n",
        "   mask = torch.zeros(output.shape[1]).to('cuda' if torch.cuda.is_available() else 'cpu').float()\n",
        "   mask[15:18] = 1.\n",
        "   num_sales_opt_model =( torch.relu(apply_model(output)) * y_std + y_mean)/3\n",
        "   price_opt_model = output * mask\n",
        "   rev_opt_model = torch.mean(torch.mean(torch.mean(num_sales_opt_model * price_opt_model, axis=1)))\n",
        "   return rev_opt_model\n",
        "\n"
      ],
      "metadata": {
        "id": "kbEpMP2eeLgM"
      },
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "revs_real, revs_opt = [], []\n",
        "\n",
        "report_frequency = len(X['test']) // batch_size // 5\n",
        "\n",
        "batch_size = 1024\n",
        "priceopt_loader = zero.data.IndexLoader(len(X_test), batch_size, device=device)\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    for iteration, batch_idx in enumerate(priceopt_loader):\n",
        "        price_opt.train()\n",
        "        optimizer.zero_grad()\n",
        "        x_batch = X['test'][batch_idx]\n",
        "        y_batch = y['test'][batch_idx]\n",
        "        rev_real = get_real_revenue()\n",
        "        rev_opt_model = get_opt_revenue()\n",
        "        loss = - rev_opt_model**2\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if iteration % report_frequency == 0:\n",
        "            print(f'(epoch) {epoch} (batch) {iteration} (loss) {rev_opt_model.item():.4f}')\n",
        "        revs_real.append(rev_real.detach().cpu().numpy())\n",
        "        revs_opt.append(rev_opt_model.detach().cpu().numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXXffgnAc_dC",
        "outputId": "53dae880-87e6-4e16-fde7-9f247c5d752d"
      },
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(epoch) 1 (batch) 0 (loss) 0.0001\n",
            "(epoch) 1 (batch) 80 (loss) 0.0067\n",
            "(epoch) 1 (batch) 160 (loss) 0.0182\n",
            "(epoch) 1 (batch) 240 (loss) 0.0311\n",
            "(epoch) 1 (batch) 320 (loss) 0.0714\n",
            "(epoch) 1 (batch) 400 (loss) 0.1387\n",
            "(epoch) 2 (batch) 0 (loss) 0.1136\n",
            "(epoch) 2 (batch) 80 (loss) 0.2476\n",
            "(epoch) 2 (batch) 160 (loss) 0.3857\n",
            "(epoch) 2 (batch) 240 (loss) 0.4935\n",
            "(epoch) 2 (batch) 320 (loss) 0.9494\n",
            "(epoch) 2 (batch) 400 (loss) 1.3732\n",
            "(epoch) 3 (batch) 0 (loss) 1.1835\n",
            "(epoch) 3 (batch) 80 (loss) 1.8812\n",
            "(epoch) 3 (batch) 160 (loss) 2.6755\n",
            "(epoch) 3 (batch) 240 (loss) 3.0473\n",
            "(epoch) 3 (batch) 320 (loss) 6.1821\n",
            "(epoch) 3 (batch) 400 (loss) 9.8743\n",
            "(epoch) 4 (batch) 0 (loss) 8.7266\n",
            "(epoch) 4 (batch) 80 (loss) 15.8733\n",
            "(epoch) 4 (batch) 160 (loss) 31.0461\n",
            "(epoch) 4 (batch) 240 (loss) 43.9006\n",
            "(epoch) 4 (batch) 320 (loss) 157.4877\n",
            "(epoch) 4 (batch) 400 (loss) 253.7248\n",
            "(epoch) 5 (batch) 0 (loss) 193.7178\n",
            "(epoch) 5 (batch) 80 (loss) 326.3239\n",
            "(epoch) 5 (batch) 160 (loss) 423.3615\n",
            "(epoch) 5 (batch) 240 (loss) 366.1051\n",
            "(epoch) 5 (batch) 320 (loss) 704.9022\n",
            "(epoch) 5 (batch) 400 (loss) 822.7667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тут вижу еще три проблемы:\n",
        "\n",
        "а) Модель FT-Transformer не доучена, соответственно плохо моделирует спрос, слабо реагирует на повышение цены\n",
        "\n",
        "б) Нужно учить две модели одновременно, по типу GAN'ов, как в статье https://arxiv.org/pdf/1706.03459.pdf, например\n",
        "\n",
        "в) И даже так возникает много вопросов к процедуре: а именно как регулировать силу оптимизаторов (в частности, с этим у меня возникли проблемы при написании курсовой: https://github.com/VileBody/OEAuctionsTermPaper"
      ],
      "metadata": {
        "id": "7wCvotNAp77r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt \n",
        "plt.plot(np.arange(len(revs_real)), revs_opt)\n",
        "plt.plot(np.arange(len(revs_real)), revs_real)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "JImroKO2k78j",
        "outputId": "026465fd-5f83-4a1c-9626-be81a36b13fa"
      },
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f295dfdfc50>]"
            ]
          },
          "metadata": {},
          "execution_count": 331
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxdZb3v8c8vO1OTNk3SpFM6l7ZAwdLSQ4tFFMoMUhwvVz1wEA/iwQHBI9NVvPjCAyp61cvF0wN4qgcBZZC+PGUeRaU0hc4DTUOndEqntE3aJDv7uX+slXRn3jvZc77v16uvrPWsZz3rt9fa+eXpsyZzziEiIpklK9kBiIhI7Cm5i4hkICV3EZEMpOQuIpKBlNxFRDJQdrIDACgrK3MTJkxIdhgiImll+fLl+5xz5V0tS4nkPmHCBCorK5MdhohIWjGzrd0t07CMiEgGUnIXEclASu4iIhlIyV1EJAMpuYuIZCAldxGRDKTkLiKSgZTcRUQSrLr2KH+r2hfXbaTETUwiIgPJ+Q+8CcCW+y6P2zbUcxcRSZIfLVnP8q0H49K2kruISJIsfKuaDbsPx6VtJXcRkSQyLC7tRpTczezbZrbWzNaY2eNmlm9mE81sqZlVmdmTZpbr183z56v85RPiErmISAaw+OT23pO7mVUA3wRmO+dOAwLA1cD9wM+dcycBB4Hr/VWuBw765T/364mISBeykpXcfdnAIDPLBgqAXcD5wFP+8kXAVf70An8ef/l8s3j9bRIRSW9JG5ZxztUAPwW24SX1OmA5cMg5F/Sr7QAq/OkKYLu/btCvPyy2YYuIZIZkDsuU4PXGJwKjgULgkv5u2MxuMLNKM6usra3tb3MiImkpXgMbkQzLXAB86Jyrdc41A88A84Bif5gGYAxQ40/XAGMB/OVDgf0dG3XOLXTOzXbOzS4v7/ItUSIiGS+ZY+7bgLlmVuCPnc8H1gGvA5/161wLPOdPL/bn8Ze/5pxzsQtZRCRzJG1Yxjm3FO/E6HvAan+dhcBtwC1mVoU3pv6Iv8ojwDC//Bbg9jjELSKSlvYcPt5uPl4nVCN6toxz7m7g7g7F1cBZXdQ9Dnyu/6GJiGSe255e1W4+aT13ERGJnWBL+1HqZJ5QFRGRGMnqcAY12TcxiYhIDAQ6JPOkPltGRESi99qGPe1OoAZbQp2GYeI15q6XdYiIxMmX/7OSMSWDePu28wE46a7nO9XRsIyISBppvb1nx8FjvdTUsIyISNqI9NZN9dxFRNJIqEN2P3y8uct6uhRSRCSNdOy4/9Oj73ZZL17PQ1dyFxGJg4499/e2HeqyXlacsrCSu4hIHEQ65q7r3EVEMpCeLSMikkbCh2W6O5kKOqEqIpJWwodlbnlyRbf1dCmkiEgaCe+5b93f0G09jbmLiKSRVTvq2qZ7OreqMXcRkRTWFAzx0BubaQy28PamfXzx4aVty3p606geHCYiksIeW7qV+1/YQMg5Rhfnt1vW02WRGpYREUlhew43AnD4WDOD83LaLaveV9/tejqhKiKSokIhx6/f3AxAU0uIvOzIU6suhRQRSVHhV8YEWxyBKLrjOqEqIpKiwofUg6FQVAlbwzIiIikqvOfeFHT8fum2KNbWsIyISEoKvxom5Bx/XrUr4nXVcxcRSVHhPffnVtREta5OqIqIpKiQ63o6EnpZh4hIiur4Yo5oZKnnLiKSel5Ys5uGxpY+r6/HD4iIpJhVOw5x438t54yxxckOpRP13EVE+ujI8SAAK7Z3/X7USOgmJhERiZiGZUREInSooYnCvGy+96c1nDKqiJOGD+53m/04F9sjJXcRkQidcc/LXPGRUW03KT32lTlJjqh7GpYREYlCNHefJpOSu4hIBlJyFxHJQEruIiIRqD3S2KksXidDY0HJXUSkF0eON/MP977SqXzf0c4JP1UouYuI9KK+m8cLfP+5NQmOJHIRJXczKzazp8xsg5mtN7OzzazUzF42s03+zxK/rpnZL82sysxWmdms+H4EEZH4itddpPEUac/9F8ALzrmTgRnAeuB24FXn3BTgVX8e4FJgiv/vBuChmEYsIpJg3eX2nEDqDn70GpmZDQXOBR4BcM41OecOAQuARX61RcBV/vQC4LfO8w5QbGajYh65iEiS7a9v6ncb8TopG8mfnYlALfAbM3vfzB42s0JghHOu9Wr+3cAIf7oC2B62/g6/rB0zu8HMKs2ssra2tu+fQEQk3jJ0WCYbmAU85JybCdRzYggGAOeco/0LwHvlnFvonJvtnJtdXl4ezaoiItKLSJL7DmCHc26pP/8UXrLf0zrc4v/c6y+vAcaGrT/GLxMRkQ5GFOXFpd1ek7tzbjew3cym+UXzgXXAYuBav+xa4Dl/ejFwjX/VzFygLmz4RkQk7cRrXHzqiMEML8qPS9uRPhXyG8BjZpYLVAPX4f1h+IOZXQ9sBT7v110CXAZUAQ1+XRGRtNWfd6R257mb5jGxvDDm7baKKLk751YAs7tYNL+Lug64qZ9xiYgk1YH6JobkZ5MTyIpLz31GnF/Nl7oXaYqIJIlzjlk/fJlb/7CSlpDr9U7UP900L0GRRU7JXUSkg9ae+uKVO/nxixt4Zf3eHuuHvyD73k+dFs/QIqbkLiLSwfWLlrVNv7xuT1TrDiuMz9Uv0VJyFxHp4PWNYTdWRjnenp2VGnc8KbmLiPQg2itlAoGek/vF00ew+gcX9SekiCi5i4h0wwyCoeiS++zxJV2WXzljNAClhbkMyc/pd2y9UXIXEemGAaEok3tOIIvBeZ2vMp87aRiQuLc3KbmLiPQg2p67GQRSYNxdyV1EpBshBy1RJvcsMyV3EZFUF+0z2w0vwcOJcXZI/NuclNxFZECrPdLIpDv+m+VbD8SkvaywLB5+WWSixtrb4kjs5kREUsvSD/cTcvDI2x/GpD0zOHnkEABGFXtPfLz+nIkxaTsakT4VUkQkI7X2qJ2DzbVHmVw+OKr1hxXmtps3Mx78wiy27K/nL5u8m6HysrM0LCMikgzPr9nN/AfeZO3OuqjWm3/K8E5lQwtymDG2GPMzepTnZGNCyV1EBrSOeXdpdWzG3gEuO30UAFfNHN1LzdjTsIyISJh7/rwuZm1NLCtky32XA5CXHQBgwRkVMWu/J0ruIjJg3fLkCrJ7eRZMrIQn+kRQcheRAeuZ92uSHULcKLmLyIBzvLmFA1HenNSdRF+/HikldxEZcL72X8vbP7O9HyaUxe8l1/2h5C4iA06sEjvAjR+fDMBL3z6XldsPxazd/lJyFxHph9aHhE0dMYSpI4YkOZoTdJ27iEgGUnIXEclASu4iIn207p6Lkx1Ct5TcRUT6wAwKclP3tKWSu4hIHyyYkfjnxURDyV1EpA9+/NkZyQ6hR0ruIjKgRPtO1O7kZqd2+kzt6EREYijYEmLynUuiWmfmuOI4RRNfSu4iktHqG4M8894OABqDoajX/+GC09puVEonqXuqV0QkBqbf/SLgPQNmUoo+ByYelNxFJCMt33qQ3XXH2+b/sGw75UPy+tSWS9VHP/ZAyV1EMtJnHvpbu/knlm1PUiTJoTF3EZEMpOQuItKL1vefphMldxEZ8M6aWNrj8sK89BvBVnIXkQGvtysdh+RncHI3s4CZvW9mf/bnJ5rZUjOrMrMnzSzXL8/z56v85RPiE7qISGwY3Wd356Aw78SwzKCcAL//ypxEhNUv0fTcvwWsD5u/H/i5c+4k4CBwvV9+PXDQL/+5X09EJGH+/c3NUdW3XnruhWFPf7z5gil89KSyvoSVUBEldzMbA1wOPOzPG3A+8JRfZRFwlT+9wJ/HXz7fry8iEndNwRD/9vyGqNbJ6iVF/a/LT22bTpe7VSPtuf8f4LtA6727w4BDzrmgP78DqPCnK4DtAP7yOr9+O2Z2g5lVmlllbW3sXlYrIgPTmpo61tTU9Wnd3rqfp48ZyjVnjwcgJ5Aepyp7jdLMrgD2OueWx3LDzrmFzrnZzrnZ5eXlsWxaRAagK371Nlf86m0c0d9N2lvPHeCCU0YAvV9ZkyoiOQU8D7jSzC4D8oEi4BdAsZll+73zMUCNX78GGAvsMLNsYCiwP+aRi4h0oS9PCugpt7f+sTh3ajlb7ru8j1ElXq89d+fcHc65Mc65CcDVwGvOuS8CrwOf9atdCzznTy/25/GXv+bS8cEMIpKW+pJtuuq5F6Xh5Y/h+jN4dBtwi5lV4Y2pP+KXPwIM88tvAW7vX4giIpH70ZL1vVfqoKuOeyq/HzUSUUXvnHsDeMOfrgbO6qLOceBzMYhNRCRqv3tna9TrdDUsk+pvWupNekcvIhITnbN7np/c03VQWcldRNLeh/vqY96meu4iIkmybudhDtQ3cd5P3+hXO+ed3Ply7I9P9crK+viCj2RL7zMGIjKgXfbLvzCiqP/J94tzxnPXs2va5ieWFXLrRdP4wpxxVBQP6nf7yaCeu4iktT2HG2Pe5tjSAgJZxpiSgpi3nShK7iIiHaTH02N6puQuItJBdpo8HKwnSu4ikjYO1jcRbAn1XrGf0uXJjz1RcheRtHC8uYWZP3yZuxevjUv737/ixGN90+XJjz1J/08gIgNCQ1MLAEtW74pL+4PDniWTCW+gUHIXEQGunDGakoIcAJoTMPQTb0ruIpJWDjY0A317hkxP8nMC/OzzZwBwrFnJXUQkIX712qZ289/705puakZn/LAT17LPGl9CcUEON31ickzaTiYldxFJC7/565aYtHP3J09tN//St89tmx46KIcV37+IOZM6vRk07Si5i0hK+39vVPHwX6pj0laWwXXzJrYry8sOxKTtVKNny4hISvvxCxtj1laaPr23T9RzF5G08/amfX1a76vnpv9YeqTUcxeRtPOlR5ZGvU74y603/PASHny9ilfW741lWClFyV1EBpz8nAC3XjSNWy+aluxQ4kbDMiIiGUjJXUQkAym5i4hkICV3Ecl4N18wJdkhJJySu4ikrM8+9LeYtDOQLoFspatlRCTlbNlXzyd++kbM2svNHnj92IH3iUUk5b1TvT+m7WXCm5WipeQuIiknFsl4II6zh1NyF5GUE4vX3N18wVQqigfFIJr0pDF3EUkJf1i2nTmTShk/rJBfvrqp9xUi8OdvnMP++saYtJVulNxFJKnuf2EDD72xGYDSwlze+96FVO+rj0nbJYW5lBTmxqStdKNhGRFJqtbEDnCgvokHX69KYjSZQ8ldRFLKT17s/vnt9yyYHlEbj31lTqzCSVtK7iKSNrq7iuauy05pm5530jDmnVSWqJBSlpK7iKSN7C6S+2dmjeGfz53UNm8MvGvau6LkLiJpI5DVfcq6/COjADhzfEmiwklpulpGRJJm8cqdUdXvqueeE/DKHvzCLL59wREmlQ2OSWzpTsldRJJm3c7DUdXvasw9/Iank4YP6XdMmULDMiKSNK297kh11XPPjrKNgULJXUSSoq6hmcZgKKp1euu5ywm97hUzG2tmr5vZOjNba2bf8stLzexlM9vk/yzxy83MfmlmVWa2ysxmxftDiEj6mXHPSyx8qzqqdcJ76V+cMw6A6aOLYhpXpojkT14QuNU5dyowF7jJzE4Fbgdedc5NAV715wEuBab4/24AHop51CIyIJmdSO73fup0Xrz5XBacUZHEiFJXr8ndObfLOfeeP30EWA9UAAuARX61RcBV/vQC4LfO8w5QbGajYh65iKSt6tqjEdV7+mtnM2Nscdt8U4dhnGkjdQK1O1ENVpnZBGAmsBQY4Zzb5S/aDYzwpyuA7WGr7fDLOrZ1g5lVmlllbW1tlGGLSLp5/N1tLN96AIDzH3gzonVCDr48b0LbfNXeyP4oSBSXQprZYOBp4Gbn3OHw/x4555yZuWg27JxbCCwEmD17dlTrikj6ueOZ1QCs+sFFEa/TEnLthmIAbr1wKh+bWh7T2DJRRMndzHLwEvtjzrln/OI9ZjbKObfLH3bZ65fXAGPDVh/jl4mIcN/zGyKuG3Ku3cMEvjR3PEMH5cQ+qAwUydUyBjwCrHfO/Sxs0WLgWn/6WuC5sPJr/Ktm5gJ1YcM3IjLAHT0ejLiuc5Dl99zHDytQYo9CJD33ecA/AqvNbIVfdidwH/AHM7se2Ap83l+2BLgMqAIagOtiGrGIpLWWUOSjsCHnGDk0H0BXxUSp1+TunHsbun3M2vwu6jvgpn7GJSIZqu5Yc8R1Q857ENhTN57NzHF6IFg09GwZEYm7J97d1jb9dtW+iNcL+b382RNKYx5TptN9uyISV8eaWrjdv1ImEqdXDG2bnqXH9/aZkruIxNWBhqao6v/kcx8BYFypTqD2h5K7iMRcUzDELU+uYPuBhrahlUi1Xh2jpz32j5K7iMTc0g/388z7Ndz57Oqoro6BE1fT5PTw1iXpnfaeiMRc0E/Qdcea+cRP34hq3eYW7/kx6rn3j66WEZGYu+43ywBYtaMu4nVmjSvm07PGMCgnAMCkcr0urz+U3EUk6ZbddQHlQ/La5v/9H8/knJPKkhhR+lNyF5GkC0/sABdPH5mkSDKHxtxFJKa8m9Qjc+qoIqruvTSO0QxcSu4iElN3RHHDUiDLyNY7UONCe1VEYub1jXt5Ytn23iv6zpum57LHi8bcRSQmQiHXdpVMb969cz4YlBXm9V5Z+kQ9dxHpl7qGZuqONXOki+e0/+vF07pcZ3hRPsOH5JOVpWvZ40XJXUT6ZcY9LzHjf7/Eht2HOy37h7CnOX713EmJDGvAU3IXkZj4Hwvf6VQ2JD+bwXne6O/0iqFUFA/i2X/5aKJDG5CU3EUkbnKzs/jd9Wcxe3wJcyeW8tfbz9dLNxJEJ1RFpE9ue2oVM8cV91gnN5DFzHElPPU19dYTTT13EemTJyu3d/kSjue/9TFy/WvX87KVYpJFe15Eovbg61XdLjtlVBH5OV5qCehqmKRRcheRqCyt3s9PXtzY5bIz/dfi/ezzZ3DyyCF6k1ISacxdRKLS1VUxrb40dxwAF5w6ggtOHZGokKQL6rmLSMS27W/ocfmnZo5JUCTSGyV3EYnYj5as73bZ+9+7MIGRSG80LCMivXrw9SpOrxjKC2t3d1unpDA3gRFJb5TcRaRHzS2hbk+gtrr1wqkJikYipWEZEenRlLue77XON+ZPSUAkEg0ldxHpZN/RRq559F32H21MdijSR0ruItLJ7U+v4q0Pavnec2uSHYr0kZK7iLQ5WN/EhNv/m1fW7wVgyer2J1A/e+YYHv/nuW03K10yfSR/v+P8hMcpvdMJVREB4Mll27jt6Z7ffzpnYilnTx7GUzeezZ9W1HD56aPJ1fNjUpKSu8gAt/fIcb76u+W8v+1Qr3UXnFEBgJnphqUUp+QuMoDd/dwaFv19a6/13vzXTzB+WGECIpJYUXIXGUAamoIsfKuaB1+vornFdVknPyeL482htvnc7Cwl9jSk5C6SgY4cb6YxGKJscB4Af6vax71L1rN2Z+f3nHb01nfPY/iQfF5cu5sD9U3MP2V4vMOVOFByF8kwa2rquOJXbwPwnYum8tOXPohovUCWce9VpzF8SD4AF08fGbcYJf6U3EXSVEvIkWXeyc3GYAuvrNvL3YvXsi/sxqOeEvunZ1Xw6ZljmD66iEG5AfJzAokIWxJEyV0kxTU0BTnaGCTLjNU1dVRuOcDilTvZfuBYn9p74HMz+MyZutIl08UluZvZJcAvgADwsHPuvnhsRyTd7D/aSDDkGDooh5aQ45X1eygalEOwxdEUDLHwrc2s3FHX7+088LkZ3PrHlXz145OYM7GU80/WizMGmpgndzMLAA8CFwI7gGVmttg5ty7W2xKJREvI0RhsoSC389fdOUdjMERzSwgzw4D9R5vIDhhHG4PsO9pIKORdCz6utIDq2npyso3KLQfZfvAYuYEsZo4rZtOeIxQNyuHZ92s4dVQRJ48c0naJYUlBDgcbmmPyWSqKB1FzyOux/8snJrN252HGlRbwzflT2Hagnumjh7YNr6h3PrCZc11fDtXnBs3OBn7gnLvYn78DwDn3b92tM3v2bFdZWRn1tra9sYhxb3yTQ4WTKK6v7mvICeUwjuWU4gwKm/YDsK9wKmX17cdGDxRMoqThQ4yuj8+h/DEUH98R93hjZX9uBfktRyhs8a7W2JE/hTHHN7Wrszkwickt3R/HQ1klFIcOxjXOWPogVEGF7aPQvDHwjaExTMtqf8zWhsYzPav768xdTgHW3PPbj1LKiNOgdgOEgt780HFQt619nZGnw+6e7oQ16OZ7n5I6fp5BJXCsw/d0+HTYu7br9b+zCQb37YokM1vunJvd1bJ43DdcAWwPm9/hl3UM6gYzqzSzytra2j5taMtO77kX6ZLYAQxHQfP+tsQOdErsAKUN1d0mdiCtEjvAsKaatsQOdErsQI+JHUirxA4wNaumLbEDnRI70GNiB9IrsQPsWXMisUPnxA69JHZIq8QOnT9Px8QO3Sd2gGUPxzYeX9JOqDrnFgILweu596WNsz5zMw3vlREqKCd3w7NkHazGFZQTKhqDhYK0lEwksH8TblAJgT0rCY6ZS6h0MtZ0FFdUQWDX+7SUnUz2zkqy9lfh8ofSfMqnyDq6CzAseIzAtr8SKp1CYM9qgidfiSssIzT8dPJe+DY0NwBGaPzHcGVTCax+Ajd4BATyIZCDG34KVuf/Qjfsg8LhuJwCsj58Azd0LOQNxk06D9u9GprqcePmkrX1r7i8IsjKJqvqJcgr8uoVDofBI7B9G3HDp8Pg4dimF7G966B0srdd1wLF47E9a6B0EmxcgpvxBaxwGDQegcEjYM8abOTpsPF5OF4H+cW0TLsUq9+PBRswF4KqV2HUDNj+Lsy+DnILoXQy/OlGCORBIAcmnANFFbD6jzC0wi/PheGnwKGtgLV9ZnIGwebXvJgGlcC4uV4SaKqH8fPgwzehoAxamqD6TW97+UVQNNqrv3cDjD8bnINtf4ed73s9xIJhgIPBI71fnhHTYcXjcM7NXjzBY5BT6MVTfjKsfByyAjBkNIybA00NcOyA1+7m12D0TNi+FM7+uvcZBw+HZ2/0YsgbAuPO9j7LBy/A0LFenUCu1/ahbd7+bzwC+cWQne99rmEnee2M/AjsXQfBRhg7x1s2eAQ0Hva2mZXjfZ6hFd729qyDyefB0T3e59/xrtdG63EeVAL7PvCO07v/ARfeA6EWcCFvPx6vg5IJsPw3kDvY2zclE8Cy4PBOr862d2DkabBzBcz7prcsOx8Wf8PbTkEpjD/H+0zb3/HWB69O2VTvMwePe9vNLfCW1bwHpRNh6BjveO/d4LU78nTv2BWU+u296+2/wuEwZIT3c88aOOkC73MdroHty6B8mrfd4HHvcxzcAqPPgL/9Cj75C6+trGwvobY0ed+ZykchdwhMmOcdt9zB3nfg2CGo3ejFtW8jfPSb3veh8Si8eCcMGQWFw2DyfDiwGfauh5KJ3v7OGeQdy0Pbvd/7rGxvPzQegQPV3nErm+odlwMfQnaetx92rfS233gEdlRCTr73fS0ohcJy7/ied2df02iP0npYRkRkIEv0sMwyYIqZTTSzXOBqYHEctiMiIt2I+bCMcy5oZl8HXsS7FPJR51wPA04iIhJrcRlzd84tAZbEo20REemdnrIvIpKBlNxFRDKQkruISAZSchcRyUBK7iIiGSjmNzH1KQizWqD3Fzl2rQzYF8NwYkVxRUdxRUdxRSdT4xrvnCvvakFKJPf+MLPK7u7QSibFFR3FFR3FFZ2BGJeGZUREMpCSu4hIBsqE5L4w2QF0Q3FFR3FFR3FFZ8DFlfZj7iIi0lkm9NxFRKQDJXcRkQyU1sndzC4xs41mVmVmtyd422PN7HUzW2dma83sW375D8ysxsxW+P8uC1vnDj/WjWZ2cRxj22Jmq/3tV/plpWb2splt8n+W+OVmZr/041plZrPiFNO0sH2ywswOm9nNydhfZvaome01szVhZVHvHzO71q+/ycyujVNcPzGzDf62nzWzYr98gpkdC9tvvw5b50z/+Ff5sVsc4or6uMX697WbuJ4Mi2mLma3wyxOyv3rIC4n/fjnn0vIf3rPiNwOTgFxgJXBqArc/CpjlTw8BPgBOBX4AfKeL+qf6MeYBE/3YA3GKbQtQ1qHsx8Dt/vTtwP3+9GXA83hvJZ4LLE3QsdsNjE/G/gLOBWYBa/q6f4BSoNr/WeJPl8QhrouAbH/6/rC4JoTX69DOu36s5sd+aRziiuq4xeP3tau4Oix/APh+IvdXD3kh4d+vdO65nwVUOeeqnXNNwBPAgkRt3Dm3yzn3nj99BFhPFy8CD7MAeMI51+ic+xCowvsMibIAWORPLwKuCiv/rfO8AxSb2ag4xzIf2Oyc6+mu5LjtL+fcW8CBLrYXzf65GHjZOXfAOXcQeBm4JNZxOedecs61vnH6HWBMT234sRU5595xXpb4bdhniVlcPejuuMX897WnuPze9+eBx3tqI9b7q4e8kPDvVzon9wpge9j8DnpOrnFjZhOAmcBSv+jr/n+xHm397xeJjdcBL5nZcjO7wS8b4Zzb5U/vBkYkIa5WV9P+ly7Z+wui3z/J2G9fxuvltZpoZu+b2Ztm9jG/rMKPJRFxRXPcEr2/Pgbscc5tCitL6P7qkBcS/v1K5+SeEsxsMPA0cLNz7jDwEDAZOAPYhfdfw0Q7xzk3C7gUuMnMzg1f6PdQknINrHnv1b0S+KNflAr7q51k7p/umNldQBB4zC/aBYxzzs0EbgF+b2ZFCQwp5Y5bB/+T9h2IhO6vLvJCm0R9v9I5udcAY8Pmx/hlCWNmOXgH8DHn3DMAzrk9zrkW51wI+A9ODCUkLF7nXI3/cy/wrB/DntbhFv/n3kTH5bsUeM85t8ePMen7yxft/klYfGb2T8AVwBf9xIA/7LHfn16ON5491Y8hfOgmLnH14bglcn9lA58GngyLN2H7q6u8QBK+X+mc3JcBU8xsot8bvBpYnKiN+2N6jwDrnXM/CysPH6/+FNB6Jn8xcLWZ5ZnZRGAK3omcWMdVaGZDWqfxTsit8bffesb9WuC5sLiu8c/azwXqwv77GA/telTJ3l9hot0/LwIXmVmJPyRxkV8WU2Z2CfBd4ErnXENYebmZBaR/sIcAAAERSURBVPzpSXj7p9qP7bCZzfW/o9eEfZZYxhXtcUvk7+sFwAbnXNtwS6L2V3d5gWR8v/p6VjgV/uGdaf4A76/wXQne9jl4/7VaBazw/10G/A5Y7ZcvBkaFrXOXH+tG+nkFQw9xTcK7EmElsLZ1vwDDgFeBTcArQKlfbsCDflyrgdlx3GeFwH5gaFhZwvcX3h+XXUAz3ljm9X3ZP3hj4FX+v+viFFcV3thr63fs137dz/jHdwXwHvDJsHZm4yXbzcD/xb8TPcZxRX3cYv372lVcfvl/Ajd2qJuQ/UX3eSHh3y89fkBEJAOl87CMiIh0Q8ldRCQDKbmLiGQgJXcRkQyk5C4ikoGU3EVEMpCSu4hIBvr/q+5mIOnpRLsAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}